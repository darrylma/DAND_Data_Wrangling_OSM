{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DATA WRANGLING PROJECT - OPENSTREETMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "The purpose of this project is to choose any city in the world, download its OpenStreetMap (OSM) file and audit, clean and prase its information into an SQL database. For my project, I have chosen to explore a sample size of Kuala Lumpur, Malaysia. You may use the hyperlink below to obtain a copy of the OSM file:\n",
    "\n",
    "[Open Street Map - Kuala Lumpur](https://mapzen.com/data/metro-extracts/metro/kuala-lumpur_malaysia/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data\n",
    "\n",
    "The first step was to create a sample of the OSM file that I had downloaded (refer to create_sample_file.py to see how sample file was created).\n",
    "\n",
    "Some initial explorations of the sample dataset (refer to initial_explorations.py to see how data below was generated):\n",
    "\n",
    "- **Number of nodes:** 385,679\n",
    "- **Number of ways:** 64,037\n",
    "- **Number of unique users:** 1,194"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems Encountered\n",
    "\n",
    "Whilst auditing the dataset, a few problems were identified:\n",
    "\n",
    "1. Street name naming convention inconsistencies\n",
    "2. Zipcode length inconsistencies\n",
    "3. Phone number format inconsistencies\n",
    "\n",
    "Before proceeding with the correction strategies, it was important to understand the inconsistencies.\n",
    "\n",
    "#### Auditing & Correcting Street Names\n",
    "\n",
    "Executing the audit_street_name.py code prints out a dictionary of unexpected street types and corresponding street names (e.g. 'jalan': set(['jalan 1 off jalan wawasan 4/2']))\n",
    "\n",
    "The following steps were taken to clean up the street name data:\n",
    "    \n",
    "    1. Use a mapping to correct abbreviations and mispellings\n",
    "    2. Remove preceding unit/lot/house numbers if the street name contained an expected street type\n",
    "    3. Append \"Jalan\" to street names which are known to frequently omit the street type\n",
    "    4. Correct specific inaccuracies\n",
    "    \n",
    "#### Auditing & Correcting Zipcodes\n",
    "\n",
    "Executing the audit_zipcode.py code prints out a dictionary of zipcodes deviating from the expected 5 character length and corresponding street names (e.g. '462000': set(['Lorong Utara C']))\n",
    "\n",
    "Since there were only 4 instances where the zipcode lengths were incorrect, a quick lookup on the internet helped to provide the correct zipcodes based on the corresponding street names:\n",
    "\n",
    "- '462000' --> '46200'\n",
    "- '5400' --> '54000'\n",
    "- '56000 ' --> '56000'\n",
    "- '6800' --> '68000'\n",
    "\n",
    "#### Auditing & Correcting Phone Numbers\n",
    "\n",
    "Executing the audit_phone_number.py code prints out a dictionary of all available phone number lengths and correponding phone numbers (e.g. 9: set(['356319100', '356389741', '390211288']))\n",
    "\n",
    "All phone numbers were converted to the following format +60xxxxxxxxx (i.e. 12 or 13 characters) using the steps below:\n",
    "\n",
    "1. Remove all white spaces, '-', '(' and ')'\n",
    "2. Add \"+60\" where applicable\n",
    "3. For those elements with more than one phone number, keep only the first number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Data into SQL Database\n",
    "\n",
    "Create a database and the subsequent table schema using following commands:\n",
    "\n",
    "1. sqlite3 kuala_lumpur_osm.db\n",
    "2. .read create_tables.sql\n",
    "\n",
    "Execute the create_csv_files.py code to create the nodes, nodes_tags, ways, ways_nodes, and ways_tags .csv files\n",
    "\n",
    "Import data from the .csv files into the SQL database, using following commands:\n",
    "\n",
    "1. sqlite3 kuala_lumpur_osm.db\n",
    "2. .read import_data.sql\n",
    "\n",
    "Below is a overview of the files and databases that were created using the process above:\n",
    "\n",
    "- **nodes.csv:**            31.2MB\n",
    "- **node_tags.csv:**         1.3MB\n",
    "- **ways.csv:**              3.7MB\n",
    "- **ways_tags.csv:**         5.1MB\n",
    "- **ways_nodes.csv:**       11.7MB\n",
    "- **kuala_lumpur_osm.db:**  63.6MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the Data\n",
    "\n",
    "To double check no data had been lost in the process of cleaning and parsing of data, the number of nodes, ways and unique subs were queried out from the SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 385679 nodes in the database.\n",
      "There are 64037 ways in the database.\n",
      "There are 1190 unique subs in the database.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pprint\n",
    "\n",
    "conn = sqlite3.connect(\"kuala_lumpur_osm.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT COUNT(*) FROM nodes;\")\n",
    "print 'There are {} nodes in the database.'.format(cursor.fetchall()[0][0])\n",
    "cursor.execute(\"SELECT COUNT(id) FROM ways;\")\n",
    "print 'There are {} ways in the database.'.format(cursor.fetchall()[0][0])\n",
    "cursor.execute(\"SELECT COUNT(DISTINCT(users.uid)) \\\n",
    "               FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) users;\")\n",
    "print 'There are {} unique subs in the database.'.format(cursor.fetchall()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of nodes and ways matches exactly to the query done before the dataset was cleaned and parsed. However the minor difference in unique subs is simply due to the fact that the relation entities were not parsed into the SQL database.\n",
    "\n",
    "From here, other information was extracted from the database to get a sense of the city's tastes and culture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of amenities in the area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'restaurant', 786),\n",
      " (u'bank', 226),\n",
      " (u'place_of_worship', 221),\n",
      " (u'fuel', 204),\n",
      " (u'parking', 160),\n",
      " (u'fast_food', 151)]\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT value, COUNT(*) \\\n",
    "               FROM nodes_tags \\\n",
    "               WHERE key='amenity' \\\n",
    "               GROUP BY value \\\n",
    "               ORDER BY COUNT(*) DESC \\\n",
    "               LIMIT 6;\")\n",
    "pprint.pprint(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of cuisines in the area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'chinese', 112), (u'malaysian', 50), (u'indian', 48)]\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT value, COUNT(*) \\\n",
    "               FROM nodes_tags cuisine \\\n",
    "               WHERE key='cuisine' \\\n",
    "               GROUP BY value \\\n",
    "               ORDER BY COUNT(*) DESC \\\n",
    "               LIMIT 3;\")\n",
    "pprint.pprint(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fast food restaurants by popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'KFC', 35), (u\"McDonald's\", 21), (u'Subway', 14)]\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT value, COUNT(*) \\\n",
    "               FROM nodes_tags amenity_names, \\\n",
    "                   (SELECT id \\\n",
    "                   FROM nodes_tags \\\n",
    "                   WHERE key='amenity' \\\n",
    "                   AND value='fast_food') amenity\\\n",
    "               WHERE amenity_names.id=amenity.id \\\n",
    "               AND key='name' \\\n",
    "               GROUP BY value \\\n",
    "               ORDER BY COUNT(*) DESC \\\n",
    "               LIMIT 3;\")\n",
    "pprint.pprint(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Banks by popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Maybank', 33), (u'Public Bank', 18), (u'CIMB', 13)]\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT value, COUNT(*) \\\n",
    "               FROM nodes_tags amenity_names, \\\n",
    "                   (SELECT id \\\n",
    "                   FROM nodes_tags \\\n",
    "                   WHERE key='amenity' \\\n",
    "                   AND value='bank') amenity\\\n",
    "               WHERE amenity_names.id=amenity.id \\\n",
    "               AND key='name' \\\n",
    "               GROUP BY value \\\n",
    "               ORDER BY COUNT(*) DESC \\\n",
    "               LIMIT 3;\")\n",
    "pprint.pprint(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fueling stations by popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Petronas', 42), (u'Shell', 27), (u'Petron', 21)]\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT value, COUNT(*) \\\n",
    "               FROM nodes_tags amenity_names, \\\n",
    "                   (SELECT id \\\n",
    "                   FROM nodes_tags \\\n",
    "                   WHERE key='amenity' \\\n",
    "                   AND value='fuel') amenity\\\n",
    "               WHERE amenity_names.id=amenity.id \\\n",
    "               AND key='name' \\\n",
    "               GROUP BY value \\\n",
    "               ORDER BY COUNT(*) DESC \\\n",
    "               LIMIT 3;\")\n",
    "pprint.pprint(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few conclusions that we can draw from the data extracted above:\n",
    "\n",
    "1. Based on the number of amenities, it would appear that the people of Kuala Lumpur love to eat more than anything else\n",
    "2. Their cuisine of choice is Chinese but if required to get a quick bite, they prefer KFC over McDonald's or Subway\n",
    "3. Based on the popularity of the banks and fueling stations, it appear that in general, the consumers' confidence in local corporations (i.e. Maybank and Petronas are Malaysian companies) is healthy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Ideas about the Dataset\n",
    "\n",
    "In general, the quality of the Kuala Lumpur OSM dataset was fairly reasonable. A few corrections were required to clean the street names, zipcodes and phone numbers, but overall, the corrections were not extensive. Unfortuntely because OSM is a human-modified project, data will always be inconsistent. The best way to ensure uniformaity is to control input at the source. That is, to limit variability by forcing contributors to select inputs from a list of values and/or implementing business rules to reject incorrect formats. However, the downside to this is:\n",
    "\n",
    "1. This may hamper the process of contributing, thereby reducing the number of submissions\n",
    "2. Formats differ from country to country so it is hard to have a single standardized format\n",
    "\n",
    "Case in point, in many countries, the street type appears at the end of the street name (e.g. Lincoln Avenue). However in Malaysia, the street type appears at the beginning of the street name (e.g. Jalan Travers).\n",
    "\n",
    "Perhaps, to improve the accuracy of the data in the future, information such as zipcode or phone number can be cross-validated with other sources (e.g. Google Maps) and prompts can be provided at the point of submission to provide an option for users to correct inconsistencies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
